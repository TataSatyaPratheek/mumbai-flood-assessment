#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Vulnerability analysis for Mumbai flood assessment.
"""

import os
import sys
import numpy as np
import pandas as pd
import geopandas as gpd
import rasterio
from rasterio.mask import mask
from rasterio.transform import from_origin
from shapely.geometry import mapping
import matplotlib.pyplot as plt
from pathlib import Path

# Add the project root directory to the Python path
project_root = Path(__file__).resolve().parent.parent.parent

def calculate_physical_vulnerability():
    """
    Calculate physical vulnerability based on elevation and slope.
    """
    print("Calculating physical vulnerability...")
    
    # Check if we have elevation data
    dem_path = project_root / "data/raw/dem/mumbai_dem.tif"
    wards_path = project_root / "data/raw/boundaries/mumbai_wards.shp"
    
    if not dem_path.exists():
        print(f"DEM file not found: {dem_path}")
        print("Creating a synthetic DEM for demonstration...")
        
        # Create a synthetic DEM if one doesn't exist
        try:
            # Ensure the directory exists
            dem_dir = dem_path.parent
            dem_dir.mkdir(parents=True, exist_ok=True)
            
            # Create a simple synthetic DEM
            # Higher values on the east, lower on the west (like Mumbai's actual topography)
            width, height = 300, 400
            dem_data = np.zeros((height, width), dtype=np.float32)
            
            # Create a gradient from west to east (higher on the east)
            for i in range(width):
                dem_data[:, i] = i / width * 100  # 0-100m elevation range
                
            # Add some random variation
            dem_data += np.random.normal(0, 5, size=(height, width))
            
            # Add some lower areas near the coast (west)
            dem_data[:, :width//5] = np.random.normal(2, 1, size=(height, width//5))
            
            # Set transform
            transform = from_origin(72.75, 19.25, 0.001, 0.001)  # Approximate resolution
            
            # Write synthetic DEM
            with rasterio.open(
                dem_path, 'w',
                driver='GTiff',
                height=height,
                width=width,
                count=1,
                dtype=dem_data.dtype,
                crs='+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs',
                transform=transform,
            ) as dst:
                dst.write(dem_data, 1)
                
            print(f"Created synthetic DEM at {dem_path}")
        except Exception as e:
            print(f"Failed to create synthetic DEM: {e}")
            return None
    
    if not wards_path.exists():
        print(f"Wards file not found: {wards_path}")
        return None
    
    # Load wards and DEM
    wards = gpd.read_file(wards_path)
    
    # Initialize dataframe for results
    vulnerability = pd.DataFrame({
        'ward_id': wards['ward_id'] if 'ward_id' in wards.columns else range(1, len(wards) + 1)
    })
    
    # Calculate statistics for each ward
    elevation_stats = []
    
    with rasterio.open(dem_path) as src:
        # Ensure wards are in the same CRS as the DEM
        wards = wards.to_crs(src.crs)
        
        for idx, ward in wards.iterrows():
            # Get ward geometry
            geom = [mapping(ward.geometry)]
            
            # Mask the DEM with the ward geometry
            try:
                out_image, out_transform = mask(src, geom, crop=True)
                
                # Get valid data (exclude nodata values)
                data = out_image[0]
                valid_data = data[data != src.nodata] if src.nodata is not None else data.flatten()
                
                if len(valid_data) > 0:
                    # Calculate statistics
                    elevation_mean = float(np.mean(valid_data))
                    elevation_min = float(np.min(valid_data))
                    elevation_max = float(np.max(valid_data))
                    
                    # Calculate percentage of area below certain thresholds
                    pct_below_5m = float(np.sum(valid_data < 5) / len(valid_data) * 100)
                    pct_below_10m = float(np.sum(valid_data < 10) / len(valid_data) * 100)
                else:
                    elevation_mean = elevation_min = elevation_max = 0
                    pct_below_5m = pct_below_10m = 0
            except Exception as e:
                print(f"Error processing ward {idx}: {e}")
                elevation_mean = elevation_min = elevation_max = 0
                pct_below_5m = pct_below_10m = 0
            
            # Store statistics
            elevation_stats.append({
                'ward_id': ward['ward_id'] if 'ward_id' in ward else f"W{idx+1:02d}",
                'elevation_mean': elevation_mean,
                'elevation_min': elevation_min,
                'elevation_max': elevation_max,
                'pct_below_5m': pct_below_5m,
                'pct_below_10m': pct_below_10m
            })
    
    # Create dataframe
    elevation_df = pd.DataFrame(elevation_stats)
    
    # Merge with wards
    vulnerability = pd.merge(vulnerability, elevation_df, on='ward_id')
    
    # Calculate physical vulnerability index
    # Higher value = higher vulnerability
    # Simple formula: normalize and weight low elevation and high percentage below thresholds
    
    # Normalize each factor to 0-1 range
    for col in ['elevation_mean', 'elevation_min']:
        if vulnerability[col].max() > vulnerability[col].min():
            vulnerability[f'{col}_norm'] = 1 - ((vulnerability[col] - vulnerability[col].min()) / 
                                         (vulnerability[col].max() - vulnerability[col].min()))
        else:
            vulnerability[f'{col}_norm'] = 0
    
    for col in ['pct_below_5m', 'pct_below_10m']:
        if vulnerability[col].max() > vulnerability[col].min():
            vulnerability[f'{col}_norm'] = ((vulnerability[col] - vulnerability[col].min()) / 
                                     (vulnerability[col].max() - vulnerability[col].min()))
        else:
            vulnerability[f'{col}_norm'] = 0
    
    # Calculate physical vulnerability index
    weights = {
        'elevation_mean_norm': 0.3,
        'elevation_min_norm': 0.3,
        'pct_below_5m_norm': 0.25,
        'pct_below_10m_norm': 0.15
    }
    
    vulnerability['physical_vulnerability'] = sum(vulnerability[col] * weight 
                                                for col, weight in weights.items())
    
    # Scale to 0-100 for interpretability
    vulnerability['physical_vulnerability'] = vulnerability['physical_vulnerability'] * 100
    
    # Save to file
    output_dir = project_root / "data/processed/vulnerability"
    output_dir.mkdir(parents=True, exist_ok=True)
    output_file = output_dir / "physical_vulnerability.csv"
    vulnerability.to_csv(output_file, index=False)
    
    print(f"Physical vulnerability calculated and saved to {output_file}")
    
    return vulnerability

def calculate_socioeconomic_vulnerability():
    """
    Calculate socioeconomic vulnerability based on census data.
    """
    print("Calculating socioeconomic vulnerability...")
    
    # Check if we have census data
    census_path = project_root / "data/raw/census/mumbai_ward_census_synthetic.csv"
    
    if not census_path.exists():
        print(f"Census file not found: {census_path}")
        return None
    
    # Load census data
    census = pd.read_csv(census_path)
    
    # Calculate socioeconomic vulnerability index
    # Higher value = higher vulnerability
    
    # Normalize each factor to 0-1 range
    factors = [
        'population_density',  # Higher density = higher vulnerability
        'poverty_index',       # Higher poverty = higher vulnerability
        'vulnerable_population_pct', # Higher vulnerable population = higher vulnerability
        'slum_household_pct'   # Higher slum percentage = higher vulnerability
    ]
    
    # Initialize vulnerability dataframe
    vulnerability = census[['ward_id', 'ward_name']].copy()
    
    # Normalize factors
    for factor in factors:
        if factor in census.columns:
            if census[factor].max() > census[factor].min():
                vulnerability[f'{factor}_norm'] = ((census[factor] - census[factor].min()) / 
                                         (census[factor].max() - census[factor].min()))
            else:
                vulnerability[f'{factor}_norm'] = 0
    
    # For concrete building percentage, higher percentage = lower vulnerability
    if 'concrete_building_pct' in census.columns:
        if census['concrete_building_pct'].max() > census['concrete_building_pct'].min():
            vulnerability['concrete_building_pct_norm'] = 1 - ((census['concrete_building_pct'] - census['concrete_building_pct'].min()) / 
                                                    (census['concrete_building_pct'].max() - census['concrete_building_pct'].min()))
        else:
            vulnerability['concrete_building_pct_norm'] = 0
        factors.append('concrete_building_pct')
    
    # Calculate socioeconomic vulnerability index with weights
    weights = {
        'population_density_norm': 0.25,
        'poverty_index_norm': 0.25,
        'vulnerable_population_pct_norm': 0.2,
        'slum_household_pct_norm': 0.2,
        'concrete_building_pct_norm': 0.1
    }
    
    # Calculate weighted sum of available factors
    vulnerability['socioeconomic_vulnerability'] = 0
    total_weight = 0
    
    for factor, weight in weights.items():
        if factor in vulnerability.columns:
            vulnerability['socioeconomic_vulnerability'] += vulnerability[factor] * weight
            total_weight += weight
    
    # Normalize by total weight used
    if total_weight > 0:
        vulnerability['socioeconomic_vulnerability'] /= total_weight
    
    # Scale to 0-100 for interpretability
    vulnerability['socioeconomic_vulnerability'] *= 100
    
    # Save to file
    output_dir = project_root / "data/processed/vulnerability"
    output_dir.mkdir(parents=True, exist_ok=True)
    output_file = output_dir / "socioeconomic_vulnerability.csv"
    vulnerability.to_csv(output_file, index=False)
    
    print(f"Socioeconomic vulnerability calculated and saved to {output_file}")
    
    return vulnerability

def calculate_overall_vulnerability():
    """
    Calculate overall vulnerability by combining physical and socioeconomic factors.
    """
    print("Calculating overall vulnerability...")
    
    # Load physical and socioeconomic vulnerability
    phys_path = project_root / "data/processed/vulnerability/physical_vulnerability.csv"
    socio_path = project_root / "data/processed/vulnerability/socioeconomic_vulnerability.csv"
    
    # Check if we need to generate physical vulnerability
    if not phys_path.exists() and socio_path.exists():
        print("Physical vulnerability file not found. Generating it now...")
        physical = calculate_physical_vulnerability()
        if physical is None:
            print("Failed to calculate physical vulnerability.")
            # Fallback to using only socioeconomic data
            socioeconomic = pd.read_csv(socio_path)
            overall = socioeconomic[['ward_id', 'socioeconomic_vulnerability']].copy()
            overall['physical_vulnerability'] = 50.0  # Default middle value
            overall['overall_vulnerability'] = overall['socioeconomic_vulnerability']
        else:
            socioeconomic = pd.read_csv(socio_path)
            # Merge data
            overall = pd.merge(physical[['ward_id', 'physical_vulnerability']], 
                            socioeconomic[['ward_id', 'socioeconomic_vulnerability']], 
                            on='ward_id')
            
            # Calculate overall vulnerability as weighted sum
            weights = {
                'physical_vulnerability': 0.6,
                'socioeconomic_vulnerability': 0.4
            }
            
            overall['overall_vulnerability'] = (
                overall['physical_vulnerability'] * weights['physical_vulnerability'] +
                overall['socioeconomic_vulnerability'] * weights['socioeconomic_vulnerability']
            )
    elif not socio_path.exists():
        print("Socioeconomic vulnerability file not found.")
        return None
    else:
        # Load data
        physical = pd.read_csv(phys_path)
        socioeconomic = pd.read_csv(socio_path)
        
        # Merge data
        overall = pd.merge(physical[['ward_id', 'physical_vulnerability']], 
                        socioeconomic[['ward_id', 'socioeconomic_vulnerability']], 
                        on='ward_id')
        
        # Calculate overall vulnerability as weighted sum
        weights = {
            'physical_vulnerability': 0.6,
            'socioeconomic_vulnerability': 0.4
        }
        
        overall['overall_vulnerability'] = (
            overall['physical_vulnerability'] * weights['physical_vulnerability'] +
            overall['socioeconomic_vulnerability'] * weights['socioeconomic_vulnerability']
        )
    
    # Save to file
    output_dir = project_root / "data/processed/vulnerability"
    output_dir.mkdir(parents=True, exist_ok=True)
    output_file = output_dir / "overall_vulnerability.csv"
    overall.to_csv(output_file, index=False)
    
    print(f"Overall vulnerability calculated and saved to {output_file}")
    
    # Merge with ward boundaries for mapping
    wards_path = project_root / "data/raw/boundaries/mumbai_wards.shp"
    if wards_path.exists():
        wards = gpd.read_file(wards_path)
        
        # Ensure ward_id is string type in both dataframes
        overall['ward_id'] = overall['ward_id'].astype(str)
        if 'ward_id' in wards.columns:
            wards['ward_id'] = wards['ward_id'].astype(str)
            # Merge
            vulnerability_map = wards.merge(overall, on='ward_id')
        else:
            print("Ward ID not found in wards shapefile. Cannot create vulnerability map.")
            return overall
        
        # Save to file
        output_file = output_dir / "overall_vulnerability.shp"
        vulnerability_map.to_file(output_file)
        
        print(f"Vulnerability map saved to {output_file}")
        
        # Create a simple map
        fig, ax = plt.subplots(1, 1, figsize=(12, 10))
        vulnerability_map.plot(column='overall_vulnerability', cmap='YlOrRd', 
                              legend=True, ax=ax)
        ax.set_title('Overall Flood Vulnerability Index')
        
        # Save figure
        fig_path = output_dir / "vulnerability_map.png"
        plt.savefig(fig_path, dpi=300, bbox_inches='tight')
        
        print(f"Vulnerability map figure saved to {fig_path}")
    
    return overall

def main():
    """Main function to calculate vulnerability indices."""
    # Calculate physical vulnerability
    physical = calculate_physical_vulnerability()
    
    # Calculate socioeconomic vulnerability
    socioeconomic = calculate_socioeconomic_vulnerability()
    
    # Calculate overall vulnerability
    overall = calculate_overall_vulnerability()
    
    print("Vulnerability analysis completed.")

if __name__ == "__main__":
    main()
